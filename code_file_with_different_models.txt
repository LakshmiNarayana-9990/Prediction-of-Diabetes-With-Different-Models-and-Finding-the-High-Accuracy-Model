* Importing libraries pandas, numpy and matplotlib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv(r'Documents\Machine-Learning-with-Python-master\diabete
s.csv')

df.head()

print("shape of data set is {}".format(df.shape))

df.groupby('Outcome').size()

import seaborn as sns
sns.countplot(df['Outcome'],label='count')

 df.describe()

df.info()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(df.loc[:,df.columns!='O
utcome'],df['Outcome'],stratify=df['Outcome'],random_state=66)

x_train.head()

x_test.head()

y_train.head()

y_test.head()

# K-nearest_neighbors classifer
list_of_training_accuracy = []
list_of_testing_accuracy = []
from sklearn.neighbors import KNeighborsClassifier
training_accuracy = []
testing_accuracy = []
neighbors = list(range(1,10))
for no_of_neighbors in neighbors:
 kn = KNeighborsClassifier(n_neighbors=no_of_neighbors).fit(x_train,y
_train)
 y_pre = kn.predict(x_test)
 print("predicted values of k = {} is ".format(no_of_neighbors))
 print(y_pre)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
for no_of_neighbors in neighbors:
 kn = KNeighborsClassifier(n_neighbors=no_of_neighbors).fit(x_train,y
_train)
 training_accuracy.append(kn.score(x_train,y_train))
 testing_accuracy.append(kn.score(x_test,y_test))
print("list of training accuracy of differnt k values models")
print(training_accuracy)
print('\n')
print('list of testing accuracy of differnt k values models')
print(testing_accuracy)

plt.plot(neighbors,training_accuracy,label="training_accuaracy")
plt.plot(neighbors,testing_accuracy,label="testing_accuracy")
plt.ylabel('accuracy')
plt.xlabel('neighbors')
plt.legend()
plt.savefig('knn_accuracy_comapare_model')

 # from the above figure we can say that we have to neighbor some where a
round 9
kn = KNeighborsClassifier(n_neighbors = 9).fit(x_train,y_train)
list_of_training_accuracy.append(kn.score(x_train,y_train))
list_of_testing_accuracy.append(kn.score(x_test,y_test))
print("Accuracy of the K-Neares_neighbors_classifer on training set is "
,kn.score(x_train,y_train))
print("Accuracy of the K-Neares_neighbors_classifer on testing set is ",
kn.score(x_test,y_test))
print()
print("Confusion Matrix ")
print(confusion_matrix(y_test,kn.predict(x_test)))
print()
print("Report")
print(classification_report(y_test,kn.predict(x_test)))

# logistic Regression
from sklearn.linear_model import LogisticRegression
lgre = LogisticRegression().fit(x_train,y_train)
ypre = lgre.predict(x_test)
print("predicted values",ypre)
print("test set values",list(y_test))
list_of_training_accuracy.append(lgre.score(x_train,y_train))
list_of_testing_accuracy.append(lgre.score(x_test,y_test))
print()
print("Accuracy of Logistic_Regression on training set is ",lgre.score(x
_train,y_train))
print("Accuracy of Logistic_Regression on testing set is ",lgre.score(x_
test,y_test))
Report
 precision recall f1-score support
 0 0.82 0.84 0.83 125
 1 0.69 0.66 0.67 67
 accuracy 0.78 192
 macro avg 0.75 0.75 0.75 192
weighted avg 0.77 0.78 0.77 192
print()
print("Confusion Matrix ")
print(confusion_matrix(y_test,lgre.predict(x_test)))
print()
print("Report")
print(classification_report(y_test,lgre.predict(x_test)))

#decision trees
from sklearn.tree import DecisionTreeClassifier
dtree = DecisionTreeClassifier(max_depth = 3).fit(x_train,y_train)
ypre=dtree.predict(x_test)
print("Predicted values of Outcome using Decison Trees classfier")
print(ypre)
print()
print("actual values of Outcome of the order set")
print(list(y_test))
list_of_training_accuracy.append(dtree.score(x_train,y_train))
list_of_testing_accuracy.append(dtree.score(x_test,y_test))
print()
print("Accuracy of Decision Trees on training set is ",dtree.score(x_tra
in,y_train))
print("Accuracy of Decision Trees on testing set is ",dtree.score(x_test
,y_test))
print()
print("Confusion Matrix ")
print(confusion_matrix(y_test,kn.predict(x_test)))
print()
print("Report")
print(classification_report(y_test,kn.predict(x_test)))

 #support vector Machine
from sklearn.svm import SVC
svc = SVC()
svc.fit(x_train, y_train)
print("Accuracy on training set: {:.2f}".format(svc.score(x_train, y_tra
in)))
print("Accuracy on test set: {:.2f}".format(svc.score(x_test, y_test)))
print()
print("Confusion Matrix ")
print(confusion_matrix(y_test,kn.predict(x_test)))
print()
print("Report")
print(classification_report(y_test,kn.predict(x_test)))

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.fit_transform(x_test)
svc = SVC()
svc.fit(x_train_scaled, y_train)
print("Accuracy on training set: {:.2f}".format(svc.score(x_train_scaled
, y_train)))
print("Accuracy on test set: {:.2f}".format(svc.score(x_test_scaled, y_t
est)))
print()
print("Confusion Matrix ")
print(confusion_matrix(y_test,kn.predict(x_test)))
print()
print("Report")
print(classification_report(y_test,kn.predict(x_test)))

svc = SVC(C=1000)
svc.fit(x_train_scaled, y_train)
list_of_training_accuracy.append(svc.score(x_train_scaled,y_train))
list_of_testing_accuracy.append(svc.score(x_test_scaled,y_test))
print("Accuracy on training set: {:.3f}".format(
 svc.score(x_train_scaled, y_train)))
print("Accuracy on test set: {:.3f}".format(svc.score(x_test_scaled, y_t
est)))
print()
print("Confusion Matrix ")
print(confusion_matrix(y_test,kn.predict(x_test)))
print()
print("Report")
print(classification_report(y_test,kn.predict(x_test)))

list_of_models=['knn','logreg','decision trees','svm']
plt.bar(list_of_models,list_of_testing_accuracy,width = 0.25)
plt.xlabel('models')
plt.ylabel('accuracy')
plt.title('Plot between the different models and accuracy')

table = pd.DataFrame({'Model_name':list_of_models,'Accuracy':list_of_tes
ting_accuracy})
print(table)
